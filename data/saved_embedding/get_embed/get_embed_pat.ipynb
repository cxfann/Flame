{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dill\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "class LearnablePositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0, max_len=1000):\n",
    "        super(LearnablePositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.embeddings = nn.Embedding(max_len, d_model)\n",
    "\n",
    "        initrange = 0.1\n",
    "        self.embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos = torch.arange(0, x.size(1), device=x.device).int().unsqueeze(0)\n",
    "        x = x + self.embeddings(pos).expand_as(x)\n",
    "        return x\n",
    "\n",
    "class PatientEncoder(nn.Module): \n",
    "    def __init__(self, args, voc_size):\n",
    "        super(PatientEncoder, self).__init__()\n",
    "        self.args = args\n",
    "        self.voc_size = voc_size\n",
    "        self.emb_dim = args.embed_dim \n",
    "        self.device = torch.device('cuda:{}'.format(args.cuda))\n",
    "\n",
    "        self.special_tokens = {'CLS': torch.LongTensor([0,]).to(self.device), 'SEP': torch.LongTensor([1,]).to(self.device)}\n",
    "        \n",
    "        self.segment_embedding = nn.Embedding(2, self.emb_dim)\n",
    "\n",
    "        if args.patient_seperate == False:\n",
    "            self.embeddings = nn.ModuleList(\n",
    "            [nn.Embedding(voc_size[i], self.emb_dim) for i in range(2)])\n",
    "            self.special_embeddings = nn.Embedding(2, self.emb_dim) \n",
    "            self.transformer_visit = nn.TransformerEncoder(\n",
    "                nn.TransformerEncoderLayer(d_model=self.emb_dim, nhead=args.nhead, dropout=args.dropout),\n",
    "                num_layers=args.encoder_layers\n",
    "            )\n",
    "            self.positional_embedding_layer_disease = LearnablePositionalEncoding(d_model=args.embed_dim)\n",
    "            self.positional_embedding_layer_procedure = LearnablePositionalEncoding(d_model=args.embed_dim)\n",
    "            self.patient_encoder = self.patient_encoder_unified\n",
    "        else:\n",
    "            self.embeddings = nn.ModuleList(\n",
    "            [nn.Embedding(voc_size[i], self.emb_dim//2) for i in range(2)])\n",
    "            self.special_embeddings = nn.Embedding(2, self.emb_dim//2)\n",
    "            self.transformer_disease = nn.TransformerEncoder(\n",
    "                nn.TransformerEncoderLayer(d_model=self.emb_dim//2, nhead=args.nhead, dropout=args.dropout),\n",
    "                num_layers=args.encoder_layers\n",
    "            )\n",
    "            self.transformer_procedure = nn.TransformerEncoder(\n",
    "                nn.TransformerEncoderLayer(d_model=self.emb_dim//2, nhead=args.nhead, dropout=args.dropout),\n",
    "                num_layers=args.encoder_layers\n",
    "            )\n",
    "\n",
    "            self.patient_layer = nn.Sequential(\n",
    "                nn.Linear(self.emb_dim, self.emb_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(self.emb_dim, self.emb_dim),\n",
    "            )\n",
    "\n",
    "            self.positional_embedding_layer_disease = LearnablePositionalEncoding(d_model=args.embed_dim//2)\n",
    "            self.positional_embedding_layer_procedure = LearnablePositionalEncoding(d_model=args.embed_dim//2)\n",
    "\n",
    "            self.patient_encoder = self.patient_encoder_seperate\n",
    "        \n",
    "    def patient_encoder_seperate(self, batch_visits):\n",
    "        device = self.device\n",
    "\n",
    "        batch_disease_repr, batch_procedure_repr = [], []\n",
    "        for adm in batch_visits:\n",
    "            # 对每次访问：\n",
    "            diseases = adm[0]\n",
    "            procedures = adm[1]\n",
    "\n",
    "            disease_embedding = self.embeddings[0](torch.LongTensor(diseases).unsqueeze(dim=1).to(self.device)) # (n, 1, dim/2)\n",
    "            procedure_embedding = self.embeddings[1](torch.LongTensor(procedures).unsqueeze(dim=1).to(self.device)) # (m, 1, dim/2)\n",
    "\n",
    "            # 加入CLS token\n",
    "            cls_embedding_dis = self.special_embeddings(self.special_tokens['CLS']).unsqueeze(dim=1)  # (1, 1, dim/2)\n",
    "            cls_embedding_pro = self.special_embeddings(self.special_tokens['SEP']).unsqueeze(dim=1)  # (1, 1, dim/2)\n",
    "            disease_embedding = torch.cat((cls_embedding_dis, disease_embedding), dim=0)  # (n+1, 1, dim/2)\n",
    "            procedure_embedding = torch.cat((cls_embedding_pro, procedure_embedding), dim=0) # (m+1, 1, dim/2)\n",
    "\n",
    "            disease_embedding = self.positional_embedding_layer_disease(disease_embedding)\n",
    "            procedure_embedding = self.positional_embedding_layer_procedure(procedure_embedding)\n",
    "\n",
    "            disease_representation = self.transformer_disease(disease_embedding)[0]  # (n+1,1,dim/2)\n",
    "            procedure_representation = self.transformer_procedure(procedure_embedding)[0] # (m+1,1,dim/2)\n",
    "\n",
    "            disease_representation = disease_representation.mean(dim=0)  # (1,1,dim/2)\n",
    "            procedure_representation = procedure_representation.mean(dim=0)  # (1,1,dim/2)\n",
    "\n",
    "            disease_representation = torch.reshape(disease_representation, (1,1,-1))  # (1,1,dim/2)\n",
    "            procedure_representation = torch.reshape(procedure_representation, (1,1,-1))  # (1,1,dim/2)\n",
    "\n",
    "            batch_disease_repr.append(disease_representation)\n",
    "            batch_procedure_repr.append(procedure_representation)\n",
    "        \n",
    "        batch_disease_repr = torch.cat(batch_disease_repr, dim=1).to(device) # (1, B, dim/2)\n",
    "        batch_procedure_repr = torch.cat(batch_procedure_repr, dim=1).to(device) #  (1, B, dim/2)\n",
    "\n",
    "        batch_repr = torch.cat((batch_disease_repr, batch_procedure_repr), dim=-1)  # (1, B, dim)\n",
    "        batch_repr = batch_repr.squeeze(dim=0)  # (B, dim)\n",
    "        # batch_repr = self.patient_layer(batch_repr)  # (B, dim)\n",
    "\n",
    "        return batch_repr\n",
    "    \n",
    "    def patient_encoder_unified(self, batch_visits):\n",
    "        batch_repr = []\n",
    "        for adm in batch_visits:\n",
    "            # 对每次访问：\n",
    "            diseases = adm[0]\n",
    "            procedures = adm[1]\n",
    "            disease_embedding = self.embeddings[0](torch.LongTensor(diseases).unsqueeze(dim=1).to(self.device)) # (n, 1, dim)\n",
    "            procedure_embedding = self.embeddings[1](torch.LongTensor(procedures).unsqueeze(dim=1).to(self.device))  # (m, 1, dim)\n",
    "            \n",
    "            cls_embedding = self.special_embeddings(self.special_tokens['CLS']).unsqueeze(dim=1)\n",
    "            sep_embedding = self.special_embeddings(self.special_tokens['SEP']).unsqueeze(dim=1)\n",
    "            \n",
    "            disease_embedding = torch.cat((cls_embedding, disease_embedding), dim=0)  # (n+1, 1, dim)\n",
    "            procedure_embedding = torch.cat((sep_embedding, procedure_embedding), dim=0) # (m+1, 1, dim)\n",
    "\n",
    "            disease_embedding = self.positional_embedding_layer_disease(disease_embedding)\n",
    "            procedure_embedding = self.positional_embedding_layer_procedure(procedure_embedding)\n",
    "\n",
    "            # disease_embedding = self.positional_embedding_layer(disease_embedding)\n",
    "            # procedure_embedding = self.positional_embedding_layer(procedure_embedding)\n",
    "\n",
    "            combined_embedding = torch.cat((disease_embedding, procedure_embedding), dim=0)  # (n+m+2, 1, dim)\n",
    "            # combined_embedding = torch.cat((cls_embedding, disease_embedding, sep_embedding, procedure_embedding), dim=0)  # (n+m+2, 1, dim)\n",
    "            \n",
    "            # 加入segment embedding\n",
    "            segments = torch.tensor([0] * (len(diseases) + 2) + [1] * len(procedures)).to(self.device)\n",
    "            segment_embedding = self.segment_embedding(segments).unsqueeze(dim=1)\n",
    "            input_embedding = combined_embedding + segment_embedding\n",
    "\n",
    "            visit_representation = self.transformer_visit(input_embedding)[0]\n",
    "            visit_representation = torch.reshape(visit_representation, (1,1,-1))   # (1,1,dim)\n",
    "            batch_repr.append(visit_representation)\n",
    "        batch_repr = torch.cat(batch_repr, dim=1).to(self.device)  # (1,B,dim)\n",
    "        batch_repr = batch_repr.squeeze(dim=0)  # (B,dim)\n",
    "        return batch_repr\n",
    "\n",
    "class RareMed(PatientEncoder):\n",
    "    def __init__(self, args, voc_size):\n",
    "        super(RareMed, self).__init__(args, voc_size)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        # self.mask_adapter = Adapter(self.emb_dim, args.adapter_dim)\n",
    "        self.cls_mask = nn.Linear(self.emb_dim, self.voc_size[0]+self.voc_size[1])\n",
    "\n",
    "        # self.nsp_adapter = Adapter(self.emb_dim, args.adapter_dim)\n",
    "        self.cls_nsp = nn.Linear(self.emb_dim, 1)\n",
    "\n",
    "        self.cls_final = nn.Linear(self.emb_dim, self.voc_size[2])\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # B: batch size, D: drug num, dim: embedding dimension\n",
    "        patient_repr = self.patient_encoder(input) # (B,dim)\n",
    "\n",
    "        return patient_repr\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize embedding weights.\"\"\"\n",
    "        initrange = 0.1\n",
    "        self.embeddings[0].weight.data.uniform_(-initrange, initrange)      # disease\n",
    "        self.embeddings[1].weight.data.uniform_(-initrange, initrange)      # procedure\n",
    "\n",
    "        self.segment_embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.special_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.note = ''\n",
    "        self.model_name = 'RAREMed'\n",
    "        self.dataset = 'mimic-iii'\n",
    "        self.early_stop = 10\n",
    "        self.test = False\n",
    "        self.log_dir_prefix = None\n",
    "        self.pretrain_prefix = None\n",
    "        self.cuda = 0\n",
    "        self.patient_seperate = False\n",
    "        self.seg_rel_emb = True\n",
    "        self.pretrain_nsp = False\n",
    "        self.pretrain_mask = False\n",
    "        self.pretrain_epochs = 20\n",
    "        self.mask_prob = 0\n",
    "        self.embed_dim = 512\n",
    "        self.encoder_layers = 3\n",
    "        self.nhead = 4\n",
    "        self.batch_size = 1\n",
    "        self.adapter_dim = 128\n",
    "        self.lr = 1e-5\n",
    "        self.dropout = 0.3\n",
    "        self.weight_decay = 0.1\n",
    "        self.weight_multi = 0.005\n",
    "        self.weight_ddi = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_path = 'data/data_process/output/mimic-iii/voc_final.pkl'\n",
    "data_path = 'data/data_process/output/mimic-iii/data.csv'\n",
    "model_path = 'Your/trained/RAREMed/model/path'   ##\n",
    "\n",
    "pat_embed_path = 'data/save_embedding/pat_embed_raremed.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "args = Args()\n",
    "\n",
    "voc = dill.load(open(voc_path, 'rb'))\n",
    "diag_voc, pro_voc, med_voc = voc['diag_voc'], voc['pro_voc'], voc['med_voc']\n",
    "def add_word(word, voc):\n",
    "    voc.word2idx[word] = len(voc.word2idx)\n",
    "    voc.idx2word[len(voc.idx2word)] = word\n",
    "    return voc\n",
    "add_word('[MASK]', diag_voc)\n",
    "add_word('[MASK]', pro_voc)\n",
    "voc_size = (len(diag_voc.idx2word), len(pro_voc.idx2word), len(med_voc.idx2word))\n",
    "\n",
    "model = RareMed(args, voc_size)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(f'cuda:{args.cuda}')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "\n",
    "pat_reps = dict()\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    hadm_id = int(data.loc[i, 'HADM_ID'])\n",
    "    diags = eval(data.loc[i, 'ICD_CODE'])\n",
    "    pros = eval(data.loc[i, 'PRO_CODE'])\n",
    "    patient = [[diags, pros]]\n",
    "    patient_repr = model(patient)\n",
    "    pat_reps[hadm_id] = patient_repr[0].cpu().detach()\n",
    "\n",
    "dill.dump(pat_reps, open(pat_embed_path, 'wb'))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
